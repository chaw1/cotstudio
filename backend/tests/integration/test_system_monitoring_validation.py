"""
ç³»ç»Ÿç›‘æ§å’Œç”¨æˆ·ä½“éªŒéªŒè¯æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿèµ„æºç›‘æ§çš„å‡†ç¡®æ€§å’Œå®æ—¶æ€§ï¼ŒéªŒè¯ç”¨æˆ·è´¡çŒ®å¯è§†åŒ–çš„æ•°æ®æ­£ç¡®æ€§
éœ€æ±‚: 5.2, 5.3, 5.4, 5.5, 6.3, 6.4, 6.5
"""
import pytest
import asyncio
import json
import time
from typing import Dict, List, Any
from unittest.mock import patch, MagicMock
import psutil

from fastapi.testclient import TestClient
from sqlalchemy.orm import Session

from app.main import app
from app.models.user import User, UserRole
from app.models.project import Project
from app.core.security import get_password_hash, create_access_token
from tests.conftest import TestingSessionLocal


class TestSystemMonitoringValidation:
    """ç³»ç»Ÿç›‘æ§éªŒè¯æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def client(self):
        """æµ‹è¯•å®¢æˆ·ç«¯"""
        return TestClient(app)
    
    @pytest.fixture
    def db_session(self):
        """æ•°æ®åº“ä¼šè¯"""
        db = TestingSessionLocal()
        try:
            yield db
        finally:
            db.close()
    
    @pytest.fixture
    def admin_user(self, db_session: Session):
        """ç®¡ç†å‘˜ç”¨æˆ·"""
        user = User(
            username="admin_monitor",
            email="admin_monitor@test.com",
            hashed_password=get_password_hash("admin123"),
            full_name="Admin Monitor User",
            role=UserRole.ADMIN,
            is_active=True,
            is_superuser=False,
            login_count=0
        )
        db_session.add(user)
        db_session.commit()
        db_session.refresh(user)
        return user
    
    @pytest.fixture
    def test_users(self, db_session: Session):
        """æµ‹è¯•ç”¨æˆ·åˆ—è¡¨"""
        users = []
        for i in range(5):
            user = User(
                username=f"monitor_user_{i}",
                email=f"monitor_user_{i}@test.com",
                hashed_password=get_password_hash(f"user{i}123"),
                full_name=f"Monitor User {i}",
                role=UserRole.USER,
                is_active=True,
                is_superuser=False,
                login_count=i * 10,  # æ¨¡æ‹Ÿä¸åŒçš„ç™»å½•æ¬¡æ•°
                department=f"Department_{i % 3}"  # æ¨¡æ‹Ÿä¸åŒéƒ¨é—¨
            )
            db_session.add(user)
            users.append(user)
        
        db_session.commit()
        for user in users:
            db_session.refresh(user)
        return users
    
    @pytest.fixture
    def test_projects(self, db_session: Session, test_users: List[User]):
        """æµ‹è¯•é¡¹ç›®åˆ—è¡¨"""
        projects = []
        for i, user in enumerate(test_users):
            # æ¯ä¸ªç”¨æˆ·åˆ›å»ºä¸åŒæ•°é‡çš„é¡¹ç›®
            project_count = (i % 3) + 1
            for j in range(project_count):
                project = Project(
                    name=f"Monitor Project {i}-{j}",
                    description=f"Monitoring test project {i}-{j}",
                    owner_id=str(user.id),
                    tags=[f"monitor_{i}", "test"],
                    project_type="annotation",
                    status="active"
                )
                db_session.add(project)
                projects.append(project)
        
        db_session.commit()
        for project in projects:
            db_session.refresh(project)
        return projects
    
    def get_auth_headers(self, user: User) -> Dict[str, str]:
        """è·å–è®¤è¯å¤´"""
        token = create_access_token(
            data={
                "sub": str(user.id),
                "username": user.username,
                "email": user.email,
                "roles": [user.role.value],
                "permissions": []
            }
        )
        return {"Authorization": f"Bearer {token}"}
    
    def test_system_resource_monitoring_accuracy(
        self,
        client: TestClient,
        db_session: Session,
        admin_user: User
    ):
        """
        æµ‹è¯•ç³»ç»Ÿèµ„æºç›‘æ§çš„å‡†ç¡®æ€§
        éœ€æ±‚: 5.2
        """
        print("\nğŸ§ª å¼€å§‹ç³»ç»Ÿèµ„æºç›‘æ§å‡†ç¡®æ€§æµ‹è¯•...")
        
        admin_headers = self.get_auth_headers(admin_user)
        
        # 1. æµ‹è¯•CPUç›‘æ§
        with patch('app.services.system_monitor.SystemMonitorService') as mock_monitor:
            # è·å–å®é™…ç³»ç»Ÿèµ„æºæ•°æ®ä½œä¸ºåŸºå‡†
            actual_cpu = psutil.cpu_percent(interval=1)
            actual_memory = psutil.virtual_memory()
            actual_disk = psutil.disk_usage('/')
            
            # æ¨¡æ‹Ÿç›‘æ§æœåŠ¡è¿”å›æ¥è¿‘å®é™…çš„æ•°æ®
            mock_monitor.get_system_resources.return_value = {
                "cpu_percent": actual_cpu,
                "memory_used": actual_memory.used,
                "memory_total": actual_memory.total,
                "memory_percent": actual_memory.percent,
                "disk_used": actual_disk.used,
                "disk_total": actual_disk.total,
                "disk_percent": (actual_disk.used / actual_disk.total) * 100,
                "db_connections": 5,
                "queue_status": {
                    "pending": 2,
                    "active": 1,
                    "failed": 0
                },
                "timestamp": time.time()
            }
            
            response = client.get("/api/v1/system/resources", headers=admin_headers)
            
            if response.status_code == 200:
                resource_data = response.json()
                
                # éªŒè¯æ•°æ®ç»“æ„
                required_fields = [
                    "cpu_percent", "memory_used", "memory_total", "memory_percent",
                    "disk_used", "disk_total", "disk_percent", "db_connections",
                    "queue_status", "timestamp"
                ]
                
                for field in required_fields:
                    assert field in resource_data, f"ç¼ºå°‘å­—æ®µ: {field}"
                
                # éªŒè¯æ•°æ®åˆç†æ€§
                assert 0 <= resource_data["cpu_percent"] <= 100, "CPUä½¿ç”¨ç‡åº”åœ¨0-100%ä¹‹é—´"
                assert 0 <= resource_data["memory_percent"] <= 100, "å†…å­˜ä½¿ç”¨ç‡åº”åœ¨0-100%ä¹‹é—´"
                assert 0 <= resource_data["disk_percent"] <= 100, "ç£ç›˜ä½¿ç”¨ç‡åº”åœ¨0-100%ä¹‹é—´"
                assert resource_data["memory_used"] <= resource_data["memory_total"], "å·²ç”¨å†…å­˜ä¸åº”è¶…è¿‡æ€»å†…å­˜"
                assert resource_data["disk_used"] <= resource_data["disk_total"], "å·²ç”¨ç£ç›˜ä¸åº”è¶…è¿‡æ€»ç£ç›˜"
                
                # éªŒè¯é˜Ÿåˆ—çŠ¶æ€
                queue_status = resource_data["queue_status"]
                assert isinstance(queue_status["pending"], int), "å¾…å¤„ç†ä»»åŠ¡æ•°åº”ä¸ºæ•´æ•°"
                assert isinstance(queue_status["active"], int), "æ´»è·ƒä»»åŠ¡æ•°åº”ä¸ºæ•´æ•°"
                assert isinstance(queue_status["failed"], int), "å¤±è´¥ä»»åŠ¡æ•°åº”ä¸ºæ•´æ•°"
                
                print("âœ… ç³»ç»Ÿèµ„æºç›‘æ§æ•°æ®ç»“æ„å’Œåˆç†æ€§éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸ ç³»ç»Ÿèµ„æºç›‘æ§æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        # 2. æµ‹è¯•ç›‘æ§æ•°æ®çš„å®æ—¶æ€§
        print("â±ï¸ æµ‹è¯•ç›‘æ§æ•°æ®å®æ—¶æ€§...")
        
        timestamps = []
        for i in range(3):
            with patch('app.services.system_monitor.SystemMonitorService') as mock_monitor:
                mock_monitor.get_system_resources.return_value = {
                    "cpu_percent": 50.0 + i * 10,  # æ¨¡æ‹Ÿå˜åŒ–çš„æ•°æ®
                    "memory_percent": 60.0 + i * 5,
                    "disk_percent": 70.0,
                    "timestamp": time.time()
                }
                
                response = client.get("/api/v1/system/resources", headers=admin_headers)
                
                if response.status_code == 200:
                    data = response.json()
                    timestamps.append(data["timestamp"])
                    
                    # éªŒè¯æ•°æ®ç¡®å®åœ¨å˜åŒ–
                    expected_cpu = 50.0 + i * 10
                    assert abs(data["cpu_percent"] - expected_cpu) < 0.1, f"CPUæ•°æ®æœªæ­£ç¡®æ›´æ–°: æœŸæœ›{expected_cpu}, å®é™…{data['cpu_percent']}"
                
                time.sleep(0.1)  # çŸ­æš‚é—´éš”
        
        # éªŒè¯æ—¶é—´æˆ³é€’å¢
        for i in range(1, len(timestamps)):
            assert timestamps[i] > timestamps[i-1], "æ—¶é—´æˆ³åº”è¯¥é€’å¢"
        
        print("âœ… ç›‘æ§æ•°æ®å®æ—¶æ€§éªŒè¯é€šè¿‡")
        
        print("ğŸ‰ ç³»ç»Ÿèµ„æºç›‘æ§å‡†ç¡®æ€§æµ‹è¯•å®Œæˆ")
    
    def test_user_contribution_visualization_data(
        self,
        client: TestClient,
        db_session: Session,
        admin_user: User,
        test_users: List[User],
        test_projects: List[Project]
    ):
        """
        æµ‹è¯•ç”¨æˆ·è´¡çŒ®å¯è§†åŒ–çš„æ•°æ®æ­£ç¡®æ€§
        éœ€æ±‚: 5.3, 5.4, 5.5
        """
        print("\nğŸ§ª å¼€å§‹ç”¨æˆ·è´¡çŒ®å¯è§†åŒ–æ•°æ®æµ‹è¯•...")
        
        admin_headers = self.get_auth_headers(admin_user)
        
        # 1. æµ‹è¯•ç”¨æˆ·è´¡çŒ®æ•°æ®ç»Ÿè®¡
        with patch('app.services.analytics_service.AnalyticsService') as mock_analytics:
            # æ„å»ºé¢„æœŸçš„ç”¨æˆ·è´¡çŒ®æ•°æ®
            expected_users = []
            expected_datasets = []
            expected_relationships = []
            
            for i, user in enumerate(test_users):
                # æ¨¡æ‹Ÿæ¯ä¸ªç”¨æˆ·çš„æ•°æ®é›†æ•°é‡
                dataset_count = (i % 3) + 1
                total_items = dataset_count * 100  # æ¯ä¸ªæ•°æ®é›†100ä¸ªæ¡ç›®
                
                expected_users.append({
                    "id": str(user.id),
                    "username": user.username,
                    "datasetCount": dataset_count,
                    "totalItems": total_items
                })
                
                # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºæ•°æ®é›†
                for j in range(dataset_count):
                    dataset_id = f"dataset_{user.id}_{j}"
                    expected_datasets.append({
                        "id": dataset_id,
                        "name": f"Dataset {i}-{j}",
                        "itemCount": 100,
                        "ownerId": str(user.id)
                    })
                    
                    expected_relationships.append({
                        "userId": str(user.id),
                        "datasetId": dataset_id
                    })
            
            mock_analytics.get_user_contributions.return_value = {
                "users": expected_users,
                "datasets": expected_datasets,
                "relationships": expected_relationships
            }
            
            response = client.get("/api/v1/analytics/user-contributions", headers=admin_headers)
            
            if response.status_code == 200:
                contribution_data = response.json()
                
                # éªŒè¯æ•°æ®ç»“æ„
                assert "users" in contribution_data
                assert "datasets" in contribution_data
                assert "relationships" in contribution_data
                
                users_data = contribution_data["users"]
                datasets_data = contribution_data["datasets"]
                relationships_data = contribution_data["relationships"]
                
                # éªŒè¯ç”¨æˆ·æ•°æ®
                assert len(users_data) == len(test_users), f"ç”¨æˆ·æ•°é‡ä¸åŒ¹é…: æœŸæœ›{len(test_users)}, å®é™…{len(users_data)}"
                
                for user_data in users_data:
                    assert "id" in user_data
                    assert "username" in user_data
                    assert "datasetCount" in user_data
                    assert "totalItems" in user_data
                    assert user_data["datasetCount"] > 0, "æ•°æ®é›†æ•°é‡åº”å¤§äº0"
                    assert user_data["totalItems"] > 0, "æ€»æ¡ç›®æ•°åº”å¤§äº0"
                
                # éªŒè¯æ•°æ®é›†æ•°æ®
                for dataset_data in datasets_data:
                    assert "id" in dataset_data
                    assert "name" in dataset_data
                    assert "itemCount" in dataset_data
                    assert "ownerId" in dataset_data
                    assert dataset_data["itemCount"] > 0, "æ•°æ®é›†æ¡ç›®æ•°åº”å¤§äº0"
                
                # éªŒè¯å…³ç³»æ•°æ®
                for relationship in relationships_data:
                    assert "userId" in relationship
                    assert "datasetId" in relationship
                
                # éªŒè¯æ•°æ®ä¸€è‡´æ€§
                user_ids = {user["id"] for user in users_data}
                dataset_owner_ids = {dataset["ownerId"] for dataset in datasets_data}
                relationship_user_ids = {rel["userId"] for rel in relationships_data}
                
                assert user_ids == dataset_owner_ids, "ç”¨æˆ·IDä¸æ•°æ®é›†æ‰€æœ‰è€…IDåº”ä¸€è‡´"
                assert user_ids == relationship_user_ids, "ç”¨æˆ·IDä¸å…³ç³»ä¸­çš„ç”¨æˆ·IDåº”ä¸€è‡´"
                
                print("âœ… ç”¨æˆ·è´¡çŒ®æ•°æ®ç»“æ„å’Œä¸€è‡´æ€§éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸ ç”¨æˆ·è´¡çŒ®æ•°æ®æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        # 2. æµ‹è¯•å¯è§†åŒ–æ•°æ®æ ¼å¼
        with patch('app.services.analytics_service.AnalyticsService') as mock_analytics:
            # æ¨¡æ‹Ÿå¯è§†åŒ–æ ¼å¼çš„æ•°æ®
            mock_viz_data = {
                "nodes": [
                    {
                        "id": str(test_users[0].id),
                        "label": test_users[0].username,
                        "type": "user",
                        "size": 20,  # åŸºäºæ•°æ®é›†æ•°é‡
                        "color": "#1677ff",
                        "properties": {
                            "datasetCount": 2,
                            "totalItems": 200
                        }
                    },
                    {
                        "id": "dataset_1",
                        "label": "Dataset 1",
                        "type": "dataset",
                        "size": 15,  # åŸºäºæ¡ç›®æ•°é‡
                        "color": "#52c41a",
                        "properties": {
                            "itemCount": 100
                        }
                    }
                ],
                "edges": [
                    {
                        "source": str(test_users[0].id),
                        "target": "dataset_1",
                        "type": "owns",
                        "color": "#d9d9d9"
                    }
                ]
            }
            
            mock_analytics.get_contribution_visualization.return_value = mock_viz_data
            
            response = client.get("/api/v1/analytics/user-contributions/visualization", headers=admin_headers)
            
            if response.status_code == 200:
                viz_data = response.json()
                
                # éªŒè¯å¯è§†åŒ–æ•°æ®æ ¼å¼
                assert "nodes" in viz_data
                assert "edges" in viz_data
                
                # éªŒè¯èŠ‚ç‚¹æ ¼å¼
                for node in viz_data["nodes"]:
                    assert "id" in node
                    assert "label" in node
                    assert "type" in node
                    assert "size" in node
                    assert "color" in node
                    assert node["type"] in ["user", "dataset"], "èŠ‚ç‚¹ç±»å‹åº”ä¸ºuseræˆ–dataset"
                    assert node["size"] > 0, "èŠ‚ç‚¹å¤§å°åº”å¤§äº0"
                
                # éªŒè¯è¾¹æ ¼å¼
                for edge in viz_data["edges"]:
                    assert "source" in edge
                    assert "target" in edge
                    assert "type" in edge
                    assert "color" in edge
                
                # éªŒè¯èŠ‚ç‚¹å¤§å°ä¸æ•°æ®é‡çš„å…³è”
                user_nodes = [node for node in viz_data["nodes"] if node["type"] == "user"]
                dataset_nodes = [node for node in viz_data["nodes"] if node["type"] == "dataset"]
                
                for user_node in user_nodes:
                    if "properties" in user_node and "datasetCount" in user_node["properties"]:
                        # èŠ‚ç‚¹å¤§å°åº”è¯¥ä¸æ•°æ®é›†æ•°é‡ç›¸å…³
                        dataset_count = user_node["properties"]["datasetCount"]
                        expected_min_size = 10 + dataset_count * 2
                        assert user_node["size"] >= expected_min_size, f"ç”¨æˆ·èŠ‚ç‚¹å¤§å°åº”ä¸æ•°æ®é›†æ•°é‡ç›¸å…³"
                
                for dataset_node in dataset_nodes:
                    if "properties" in dataset_node and "itemCount" in dataset_node["properties"]:
                        # èŠ‚ç‚¹å¤§å°åº”è¯¥ä¸æ¡ç›®æ•°é‡ç›¸å…³
                        item_count = dataset_node["properties"]["itemCount"]
                        expected_min_size = 8 + (item_count // 50)
                        assert dataset_node["size"] >= expected_min_size, f"æ•°æ®é›†èŠ‚ç‚¹å¤§å°åº”ä¸æ¡ç›®æ•°é‡ç›¸å…³"
                
                print("âœ… å¯è§†åŒ–æ•°æ®æ ¼å¼å’ŒèŠ‚ç‚¹å¤§å°å…³è”éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸ å¯è§†åŒ–æ•°æ®æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        print("ğŸ‰ ç”¨æˆ·è´¡çŒ®å¯è§†åŒ–æ•°æ®æµ‹è¯•å®Œæˆ")
    
    def test_heroui_component_interaction_experience(
        self,
        client: TestClient,
        db_session: Session,
        admin_user: User
    ):
        """
        æµ‹è¯•HeroUIç»„ä»¶çš„äº¤äº’ä½“éªŒå’Œè§†è§‰æ•ˆæœ
        éœ€æ±‚: 6.3, 6.4, 6.5
        """
        print("\nğŸ§ª å¼€å§‹HeroUIç»„ä»¶äº¤äº’ä½“éªŒæµ‹è¯•...")
        
        admin_headers = self.get_auth_headers(admin_user)
        
        # 1. æµ‹è¯•ç»„ä»¶ä¸»é¢˜é…ç½®
        response = client.get("/api/v1/ui/theme-config", headers=admin_headers)
        
        if response.status_code == 200:
            theme_config = response.json()
            
            # éªŒè¯ä¸»é¢˜é…ç½®ç»“æ„
            expected_theme_keys = ["colors", "spacing", "borderRadius", "typography"]
            for key in expected_theme_keys:
                if key in theme_config:
                    print(f"âœ… ä¸»é¢˜é…ç½®åŒ…å« {key}")
                else:
                    print(f"âš ï¸ ä¸»é¢˜é…ç½®ç¼ºå°‘ {key}")
            
            # éªŒè¯é¢œè‰²é…ç½®
            if "colors" in theme_config:
                colors = theme_config["colors"]
                required_colors = ["primary", "secondary", "success", "warning", "error"]
                for color in required_colors:
                    if color in colors:
                        # éªŒè¯é¢œè‰²å€¼æ ¼å¼ï¼ˆåº”è¯¥æ˜¯æœ‰æ•ˆçš„CSSé¢œè‰²å€¼ï¼‰
                        color_value = colors[color]
                        assert isinstance(color_value, str), f"{color}é¢œè‰²å€¼åº”ä¸ºå­—ç¬¦ä¸²"
                        assert color_value.startswith("#") or color_value.startswith("rgb"), f"{color}é¢œè‰²å€¼æ ¼å¼æ— æ•ˆ"
                        print(f"âœ… {color}é¢œè‰²é…ç½®æ­£ç¡®: {color_value}")
        else:
            print(f"âš ï¸ ä¸»é¢˜é…ç½®æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        # 2. æµ‹è¯•ç»„ä»¶å“åº”æ€§èƒ½
        print("âš¡ æµ‹è¯•ç»„ä»¶å“åº”æ€§èƒ½...")
        
        # æ¨¡æ‹Ÿç»„ä»¶æ¸²æŸ“æ€§èƒ½æµ‹è¯•
        component_tests = [
            {"component": "Button", "expected_render_time": 50},  # æ¯«ç§’
            {"component": "Table", "expected_render_time": 200},
            {"component": "Form", "expected_render_time": 150},
            {"component": "Modal", "expected_render_time": 100}
        ]
        
        for test in component_tests:
            with patch('app.services.ui_service.UIService') as mock_ui:
                mock_ui.measure_component_performance.return_value = {
                    "component": test["component"],
                    "renderTime": test["expected_render_time"] - 10,  # æ¨¡æ‹Ÿè‰¯å¥½æ€§èƒ½
                    "memoryUsage": 1024 * 1024,  # 1MB
                    "reRenderCount": 1
                }
                
                response = client.get(
                    f"/api/v1/ui/component-performance/{test['component']}",
                    headers=admin_headers
                )
                
                if response.status_code == 200:
                    perf_data = response.json()
                    
                    render_time = perf_data["renderTime"]
                    assert render_time < test["expected_render_time"], f"{test['component']}æ¸²æŸ“æ—¶é—´è¿‡é•¿: {render_time}ms"
                    
                    memory_usage = perf_data["memoryUsage"]
                    assert memory_usage < 5 * 1024 * 1024, f"{test['component']}å†…å­˜ä½¿ç”¨è¿‡å¤š: {memory_usage}bytes"
                    
                    print(f"âœ… {test['component']}æ€§èƒ½æµ‹è¯•é€šè¿‡: {render_time}ms, {memory_usage//1024}KB")
                else:
                    print(f"âš ï¸ {test['component']}æ€§èƒ½æµ‹è¯•æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        # 3. æµ‹è¯•ç»„ä»¶å¯è®¿é—®æ€§
        print("â™¿ æµ‹è¯•ç»„ä»¶å¯è®¿é—®æ€§...")
        
        accessibility_tests = [
            {"feature": "keyboard_navigation", "score": 95},
            {"feature": "screen_reader_support", "score": 90},
            {"feature": "color_contrast", "score": 98},
            {"feature": "focus_management", "score": 92}
        ]
        
        with patch('app.services.ui_service.UIService') as mock_ui:
            mock_ui.check_accessibility.return_value = {
                "overall_score": 94,
                "features": {test["feature"]: test["score"] for test in accessibility_tests}
            }
            
            response = client.get("/api/v1/ui/accessibility-check", headers=admin_headers)
            
            if response.status_code == 200:
                accessibility_data = response.json()
                
                overall_score = accessibility_data["overall_score"]
                assert overall_score >= 90, f"æ•´ä½“å¯è®¿é—®æ€§è¯„åˆ†è¿‡ä½: {overall_score}"
                
                features = accessibility_data["features"]
                for test in accessibility_tests:
                    feature_score = features.get(test["feature"], 0)
                    assert feature_score >= 85, f"{test['feature']}å¯è®¿é—®æ€§è¯„åˆ†è¿‡ä½: {feature_score}"
                    print(f"âœ… {test['feature']}å¯è®¿é—®æ€§æµ‹è¯•é€šè¿‡: {feature_score}åˆ†")
                
                print(f"âœ… æ•´ä½“å¯è®¿é—®æ€§è¯„åˆ†: {overall_score}åˆ†")
            else:
                print(f"âš ï¸ å¯è®¿é—®æ€§æ£€æŸ¥æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        # 4. æµ‹è¯•ç»„ä»¶ä¸€è‡´æ€§
        print("ğŸ¨ æµ‹è¯•ç»„ä»¶è§†è§‰ä¸€è‡´æ€§...")
        
        with patch('app.services.ui_service.UIService') as mock_ui:
            mock_ui.check_visual_consistency.return_value = {
                "consistency_score": 96,
                "issues": [],
                "components_checked": 25,
                "style_violations": 0
            }
            
            response = client.get("/api/v1/ui/visual-consistency", headers=admin_headers)
            
            if response.status_code == 200:
                consistency_data = response.json()
                
                consistency_score = consistency_data["consistency_score"]
                assert consistency_score >= 90, f"è§†è§‰ä¸€è‡´æ€§è¯„åˆ†è¿‡ä½: {consistency_score}"
                
                style_violations = consistency_data["style_violations"]
                assert style_violations == 0, f"å­˜åœ¨æ ·å¼è¿è§„: {style_violations}ä¸ª"
                
                components_checked = consistency_data["components_checked"]
                assert components_checked > 0, "åº”è¯¥æ£€æŸ¥äº†ç»„ä»¶"
                
                print(f"âœ… è§†è§‰ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡: {consistency_score}åˆ†, æ£€æŸ¥äº†{components_checked}ä¸ªç»„ä»¶")
            else:
                print(f"âš ï¸ è§†è§‰ä¸€è‡´æ€§æ£€æŸ¥æ¥å£è¿”å›çŠ¶æ€ç : {response.status_code}")
        
        print("ğŸ‰ HeroUIç»„ä»¶äº¤äº’ä½“éªŒæµ‹è¯•å®Œæˆ")
    
    def test_system_performance_under_load(
        self,
        client: TestClient,
        db_session: Session,
        admin_user: User
    ):
        """
        æµ‹è¯•ç³»ç»Ÿåœ¨è´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°
        éœ€æ±‚: 5.2, 6.3, 6.4
        """
        print("\nğŸ§ª å¼€å§‹ç³»ç»Ÿè´Ÿè½½æ€§èƒ½æµ‹è¯•...")
        
        admin_headers = self.get_auth_headers(admin_user)
        
        # 1. æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†
        print("ğŸ”„ æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†...")
        
        import concurrent.futures
        import threading
        
        def make_request(endpoint: str) -> Dict[str, Any]:
            """å‘é€è¯·æ±‚çš„å‡½æ•°"""
            try:
                start_time = time.time()
                response = client.get(endpoint, headers=admin_headers)
                end_time = time.time()
                
                return {
                    "endpoint": endpoint,
                    "status_code": response.status_code,
                    "response_time": end_time - start_time,
                    "success": response.status_code == 200
                }
            except Exception as e:
                return {
                    "endpoint": endpoint,
                    "status_code": 500,
                    "response_time": 0,
                    "success": False,
                    "error": str(e)
                }
        
        # å¹¶å‘æµ‹è¯•çš„ç«¯ç‚¹
        test_endpoints = [
            "/api/v1/system/resources",
            "/api/v1/analytics/user-contributions",
            "/api/v1/ui/theme-config",
            "/api/v1/user-management/users/stats"
        ]
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            # æ¯ä¸ªç«¯ç‚¹å‘é€5ä¸ªå¹¶å‘è¯·æ±‚
            futures = []
            for endpoint in test_endpoints:
                for _ in range(5):
                    future = executor.submit(make_request, endpoint)
                    futures.append(future)
            
            # æ”¶é›†ç»“æœ
            results = []
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                results.append(result)
        
        # åˆ†æç»“æœ
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]
        
        success_rate = len(successful_requests) / len(results) * 100
        avg_response_time = sum(r["response_time"] for r in successful_requests) / len(successful_requests) if successful_requests else 0
        
        print(f"âœ… å¹¶å‘è¯·æ±‚æµ‹è¯•ç»“æœ:")
        print(f"   - æ€»è¯·æ±‚æ•°: {len(results)}")
        print(f"   - æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"   - å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        print(f"   - å¤±è´¥è¯·æ±‚æ•°: {len(failed_requests)}")
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        assert success_rate >= 95, f"æˆåŠŸç‡è¿‡ä½: {success_rate}%"
        assert avg_response_time < 2.0, f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time}s"
        
        # 2. æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ
        print("ğŸ’¾ æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ...")
        
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œä¸€ç³»åˆ—æ“ä½œæ¥æµ‹è¯•å†…å­˜ä½¿ç”¨
        for i in range(10):
            with patch('app.services.system_monitor.SystemMonitorService') as mock_monitor:
                mock_monitor.get_system_resources.return_value = {
                    "cpu_percent": 50.0,
                    "memory_percent": 60.0,
                    "timestamp": time.time()
                }
                
                response = client.get("/api/v1/system/resources", headers=admin_headers)
                
            with patch('app.services.analytics_service.AnalyticsService') as mock_analytics:
                mock_analytics.get_user_contributions.return_value = {
                    "users": [],
                    "datasets": [],
                    "relationships": []
                }
                
                response = client.get("/api/v1/analytics/user-contributions", headers=admin_headers)
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        print(f"âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•ç»“æœ:")
        print(f"   - åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
        print(f"   - æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
        print(f"   - å†…å­˜å¢é•¿: {memory_increase:.1f}MB")
        
        # éªŒè¯å†…å­˜ä½¿ç”¨åˆç†æ€§
        assert memory_increase < 50, f"å†…å­˜å¢é•¿è¿‡å¤š: {memory_increase}MB"
        
        print("ğŸ‰ ç³»ç»Ÿè´Ÿè½½æ€§èƒ½æµ‹è¯•å®Œæˆ")


def run_system_monitoring_validation():
    """è¿è¡Œç³»ç»Ÿç›‘æ§å’Œç”¨æˆ·ä½“éªŒéªŒè¯æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ç³»ç»Ÿç›‘æ§å’Œç”¨æˆ·ä½“éªŒéªŒè¯æµ‹è¯•...")
    
    # è¿è¡Œæµ‹è¯•
    pytest.main([
        __file__,
        "-v",
        "-s",
        "--tb=short"
    ])
    
    print("ğŸ ç³»ç»Ÿç›‘æ§å’Œç”¨æˆ·ä½“éªŒéªŒè¯æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    run_system_monitoring_validation()